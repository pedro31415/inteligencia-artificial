# Resumo de Intelig√™ncia Artificial

## ü§ñ O que seria Intelig√™ncia Artificial?

A **Intelig√™ncia Artificial (IA)** √© o campo da ci√™ncia da computa√ß√£o que busca desenvolver sistemas ou m√°quinas capazes de **simular comportamentos inteligentes**, como **aprender**, **raciocinar**, **resolver problemas**, **perceber** o ambiente e at√© mesmo se comunicar em linguagem natural.

A IA pode ser dividida em diferentes abordagens de estudo:

---

## üìå Quest√µes √âticas:

1. Preconceitos e Discrimina√ß√£o em Algoritmos
2. Privacidade e Seguran√ßa de Dados
3. Autonomia e Controle
4. Impacto no Mercado de Trabalho
5. Transpar√™ncia e Explicabilidade
6. Responsabilidade e Accountability
7. Manipula√ß√£o e Fake News
8. √âtica no Desenvolvimento de IA
9. Impactos Ambientais
10. Riscos de Superintelig√™ncia e Controle Global

---

## üìå Categorias da IA:

### 1. **Sistemas que pensam como humanos**
- Objetivo: simular o processo de **pensamento humano**.
- Exemplo: Modelos cognitivos, como redes neurais que tentam replicar o funcionamento do c√©rebro.

### 2. **Sistemas que agem como humanos**
- Objetivo: **agir como uma pessoa**, imitando seu comportamento.
- Exemplo: Rob√¥s humanoides, assistentes virtuais (como o Siri), e o pr√≥prio ChatGPT.

### 3. **Sistemas que pensam racionalmente**
- Objetivo: **pensar de maneira l√≥gica**, baseada em regras e infer√™ncias.
- Exemplo: Sistemas especialistas baseados em l√≥gica formal.

### 4. **Sistemas que agem racionalmente**
- Objetivo: **agir da melhor forma poss√≠vel** para alcan√ßar um objetivo.
- Exemplo: Carros aut√¥nomos, agentes inteligentes que tomam decis√µes com base em situa√ß√µes.

> üí¨ O ChatGPT se encaixa principalmente como **sistema que age como humano** (processamento de linguagem natural), mas tamb√©m pode ser visto como **sistema que pensa racionalmente**.

---

## üß¨ Linhas de Pesquisa em IA:

### üîπ Simb√≥lica (ou simb√≥lica cl√°ssica)
- Representa conhecimento com **s√≠mbolos e regras l√≥gicas**.
- Exemplo: Sistemas especialistas, Prolog.

### üîπ Conexionista
- Inspira-se na **estrutura do c√©rebro humano** (redes neurais).
- Exemplo: Machine Learning e Deep Learning.

### üîπ Evolucion√°ria
- Baseada em mecanismos de **evolu√ß√£o natural**.
- Exemplo: Algoritmos Gen√©ticos e Programa√ß√£o Evolutiva.

---

## üìñ Breve Hist√≥rico

### üßê Quando surgiu o termo IA?
-  A primeira manifesta√ß√£o oficial de IA foi registrada em 1956 na
Confer√™ncia de Darthmouth.

### üíª Pesquisadores que contribu√≠ram para a cria√ß√£o do campo da IA:
-  John McCarthy: cunhou o termo intelig√™ncia artificial.
-  Marvin Minsky: Construiu o primeiro computador com base em redes
neurais. Descreveu a incapacidade do perceptron simples resolver problemas
como o XOR.
-  Nathaniel ROchester: Simulou o comportamento de redes neurais abstratas
em um computador IBM 704.
-  Norbert Wiener: Fundador da cibern√©tica. Desenvolveu estudos de sistemas
autorregulados e formulou o conceito de retroalimenta√ß√£o negativa.
- Frank Rosenblatt: Inventou o perpectron.

---

## üß† Agente, Fun√ß√£o do Agente e Agente Inteligente

- **Agente**: entidade que percebe o ambiente e age sobre ele.
- **Fun√ß√£o do agente**: mapeia percep√ß√µes para a√ß√µes.
- **Agente Inteligente**: escolhe a√ß√µes que **maximizam seu desempenho** com base nas percep√ß√µes e conhecimento.

---

## üéØ Quatro fatores que definem a racionalidade de um agente:

1. **Medi√ß√£o de desempenho**: crit√©rio para avaliar o sucesso da tarefa.
2. **Conhecimento pr√©vio**: o que o agente j√° sabe sobre o ambiente.
3. **A√ß√µes poss√≠veis**: conjunto de a√ß√µes que o agente pode realizar.
4. **Sequ√™ncia de percep√ß√µes**: hist√≥rico de tudo o que foi percebido at√© o momento.

---

## üåç Propriedades do ambiente de tarefas:

- **Observ√°vel**: o agente tem acesso total (ou n√£o) ao estado do ambiente.
- **Determin√≠stico**: o pr√≥ximo estado depende apenas do estado atual e a√ß√£o do agente.
- **Epis√≥dico**: decis√µes independentes (ou dependentes) de epis√≥dios anteriores.
- **Est√°tico**: o ambiente muda apenas com as a√ß√µes do agente.
- **Discreto**: n√∫mero finito de a√ß√µes/percep√ß√µes.
- **Agente**: o sistema que atua no ambiente.

---

## ‚öôÔ∏è Tipos de Estrutura de Agentes

### 1. Agentes Reativos Simples
- Baseados em regras simples ‚ÄúSe-ent√£o‚Äù.
- **Exemplo**: sensor de luz, rob√¥ aspirador b√°sico.

### 2. Agentes Reativos Baseados em Modelo
- T√™m mem√≥ria/estado interno.
- **Exemplo**: carro aut√¥nomo que lembra obst√°culos.

### 3. Agentes Baseados em Objetivos
- Tomam decis√µes com base em objetivos a alcan√ßar.
- **Exemplo**: rob√¥ de entrega que escolhe a melhor rota.

### 4. Agentes Baseados na Utilidade
- Avaliam qual a√ß√£o traz maior ‚Äúsatisfa√ß√£o‚Äù ou benef√≠cio.
- **Exemplo**: carro aut√¥nomo que busca o caminho mais seguro e r√°pido.

---

## üìö Agente de Aprendizagem e seus Elementos Conceituais

Um **agente de aprendizagem** melhora com o tempo, aprendendo a partir da experi√™ncia. Ele √© composto por:

### ‚Ä¢ Elemento de Desempenho:
Executa a√ß√µes com base no conhecimento atual.

### ‚Ä¢ Elemento Cr√≠tico:
Avalia o desempenho e identifica o que precisa melhorar.

### ‚Ä¢ Elemento de Aprendizado:
Atualiza o agente com base na avalia√ß√£o do elemento cr√≠tico.

### ‚Ä¢ Gerador de Problemas:
Cria novas situa√ß√µes para o agente explorar e aprender.

---

## üß© Resolu√ß√£o de Problemas por Busca ‚Äî 4 Componentes

### üîπ 1. Estado Inicial
> Situa√ß√£o de partida do problema. Define onde o agente come√ßa.

**Exemplo**: No jogo de xadrez, √© a posi√ß√£o inicial das pe√ßas.

### üîπ 2. Fun√ß√£o Sucessor
> Conjunto de a√ß√µes poss√≠veis e os estados resultantes.

**Exemplo**: Em um jogo, quais movimentos s√£o poss√≠veis a partir do estado atual.

### üîπ 3. Teste Objetivo
> Verifica se o problema foi resolvido.

**Exemplo**: Se o agente alcan√ßou o destino desejado ou resolveu o quebra-cabe√ßa.

### üîπ 4. Fun√ß√£o de Custo
> Mede o custo total de um caminho (em tempo, recursos, dist√¢ncia...).

**Exemplo**: Um GPS considera o tempo ou dist√¢ncia para sugerir a melhor rota.

---

## üîç Estrat√©gias de Busca em IA

As estrat√©gias de busca s√£o usadas por agentes para encontrar **solu√ß√µes** em um espa√ßo de estados. Podemos dividi-las em dois grandes grupos:

### üîπ 1. **Buscas sem informa√ß√£o (cegas)**
S√£o aquelas em que o agente **n√£o tem conhecimento adicional** sobre o estado al√©m das conex√µes entre eles. Ele explora o espa√ßo de maneira sistem√°tica.

---

### üî∏ **1.1 Busca em extens√£o (ou amplitude - Breadth-First Search)**

- Explora **todos os n√≥s no mesmo n√≠vel** antes de avan√ßar para o pr√≥ximo.
- Garante encontrar a **solu√ß√£o mais pr√≥xima** (menor n√∫mero de passos).
- Pode consumir muita mem√≥ria.

**Exemplo de c√≥digo**:
``` python
# 1.1 -> Breadth First Search
# FIFO
def bfs_2(graph, inital, goal):
    queue_2 = deque([(inital, [inital], 0)])

    while queue_2:
        node, result, cost = queue_2.popleft()

        if node == goal:
            return result, cost

        for neighbour, weight in graph.get(node, {}).items():
            if neighbour not in result:
                queue_2.append((neighbour, result + [neighbour], cost + weight))
    return None
```

üìå **Exemplo**: Procurar um contato na agenda telef√¥nica nome por nome.

---

### üî∏ **1.2 Busca de custo uniforme (Uniform Cost Search)**

- Expande o **n√≥ de menor custo total acumulado** primeiro.
- √â √≥tima quando os custos de a√ß√µes variam.
- Garante o **caminho de menor custo**, mas pode ser mais lenta.

**Exemplo de c√≥digo:**
``` python
# 1.2 -> Uniform Cost Search
#priority queue
def ucs(graph, result, goal):
    queue = [(0, result, [])]
    visited = set()

    while queue:
        cost, node, path = heapq.heappop(queue)

        if node in visited:
            continue
        visited.add(node)

        path = path + [node]

        if node == goal:
            return path, cost

        for neighbour, weight in graph.get(node, {}).items():
            if neighbour not in visited:
                heapq.heappush(queue, (cost + weight, neighbour, path))
    return None
```
üìå **Exemplo**: Encontrar o caminho mais barato entre duas cidades.

---

### üî∏ **1.3 Busca em profundidade (Depth-First Search)**

- Explora **o caminho mais profundo** primeiro antes de voltar.
- Usa menos mem√≥ria do que a busca em amplitude.
- Pode n√£o encontrar a melhor solu√ß√£o ou at√© entrar em loop.

**Exemplo de c√≥digo:**
``` python
# 1.3 ->  Depth First Search
# FIFO

def dfs(graph, result, goal):
    stack = [(result, [result], 0),]
    visited = set()


    while stack:
        node, path, cost = stack.pop()

        if node in visited:
            continue
        visited.add(node)

        if node == goal:
            return path, cost

        for neighbour, weight in graph.get(node, {}).items():
            if neighbour not in visited:
                stack.append((neighbour, path + [neighbour], cost + weight))
    return None
```
üìå **Exemplo**: Seguir um corredor de um labirinto at√© o fim antes de voltar.

---

### üî∏ **1.4 Busca em profundidade limitada**

- √â como a busca em profundidade, **mas com um limite de profundidade**.
- Evita loops infinitos.
- Pode **falhar** se a solu√ß√£o estiver al√©m do limite.

**Exemplo de c√≥digo:**
```python
# 1.4 -> Depth Limitedd Search
def dls(graph, result, goal, limit, path=None, cost=0):
    if path is None:
        path = [result]

    if result == goal:
        return path, cost

    if limit <= 0:
        return None

    for neighbor, weight in graph.get(result, {}).items():
        if neighbor not in path:
            result = dls(graph, neighbor, goal, limit - 1, path + [neighbor], cost + weight)
            if result:
                return result
    return None
```
üìå **Exemplo**: Procurar uma chave ca√≠da em uma escada at√© 10 degraus abaixo.

---

### üî∏ **1.5 Busca de aprofundamento iterativo**

- Combina as vantagens da busca em **amplitude e profundidade**.
- Realiza buscas em profundidade com limites que aumentam gradualmente.
- Garante encontrar a solu√ß√£o √≥tima com **baixo uso de mem√≥ria**.

**Exemplo de c√≥digo:**
```python
# 1.5 -> Irative Deepening Depth First Search
def iddfs(graph, start, goal, max_depth=10):
    for depth in range(max_depth + 1):
        result= dls(graph, start, goal, depth)
        if result:
            return result
    return None
```
üìå **Exemplo**: Procurar item perdido em uma mochila por camadas (primeiro no topo, depois mais fundo, etc.).

---

### üî∏ 1.6 **Busca Bidirecional (ou informada)**

- Parte do estado inicial e do objetivo simultaneamente.
- Reduz a complexidade de busca.
- Ex: Caminho entre duas cidades.

**Exemplo de c√≥digo**
``` python
# 1.6 Bidirectional Search
def bidirectional_bfs(graph, start, goal):
    if start == goal:
        return [start], 0

    forward_queue = deque([(start, [start], 0)])
    backward_queue = deque([(goal, [goal], 0)])

    forward_visited = {start: (0, [start])}
    backward_visited = {goal: (0, [goal])}

    while forward_queue and backward_queue:
        
        node, path, cost = forward_queue.popleft()
        for neighbor, weight in graph.get(node, {}).items():
            if neighbor not in forward_visited:
                new_cost = cost + weight
                new_path = path + [neighbor]
                forward_visited[neighbor] = (new_cost, new_path)
                forward_queue.append((neighbor, new_path, new_cost))

                if neighbor in backward_visited:
                    back_cost, back_path = backward_visited[neighbor]
                    return new_path + back_path[::-1][1:], new_cost + back_cost

        node, path, cost = backward_queue.popleft()
        for neighbor, weight in graph.get(node, {}).items():
            if neighbor not in backward_visited:
                new_cost = cost + weight
                new_path = path + [neighbor]
                backward_visited[neighbor] = (new_cost, new_path)
                backward_queue.append((neighbor, new_path, new_cost))

                if neighbor in forward_visited:
                    front_cost, front_path = forward_visited[neighbor]
                    return front_path + new_path[::-1][1:], front_cost + new_cost

    return None, float('inf')  
```

üìå **Exemplo**: Usar a dist√¢ncia em linha reta at√© o objetivo como dica para guiar a busca.

---

---

## üîπ 2. Busca Heur√≠stica

A busca heur√≠stica √© uma **estrat√©gia informada**, ou seja, ela **usa conhecimento extra (uma heur√≠stica)** para tomar decis√µes mais inteligentes sobre qual caminho seguir.

---

### üî∏ 2.1 Busca Gulosa (Greedy Best-First Search)

- Escolhe o **n√≥ com menor valor heur√≠stico**.
- **R√°pida**, mas **n√£o garante o menor custo**.
- Pode seguir por caminhos errados se a heur√≠stica n√£o for boa.

**Exemplo de c√≥digo:**
``` python
# 2.1 Greedy Best First Search

# problem algorithms Gredy Best First Search -> He need the heurisct value before the example

def greedy_best_first_search(graph, heuristics, start, goal):

    if start == goal:
        return [start]

    priority_queue = [(heuristics[start], start, [start], 0)]

    visited = set()

    while priority_queue:
        _, current_node, path, cost = heapq.heappop(priority_queue)

        if current_node == goal:
            return path, cost

        visited.add(current_node)

        for neighbor, weidth in graph.get(current_node, {}).items():
            if neighbor not in visited:
                new_path = path + [neighbor]
                new_cost = cost + weidth
                heapq.heappush(priority_queue, (heuristics[neighbor], neighbor, new_path, new_cost))
    return None
```

**Exemplo de heur√≠stica:**
``` python
heuristic = {
    "oradea": 380,
    "zerind": 374,
    "arad": 366,
    "sibiu": 253,
    "timisoara": 329,
    "lugoj": 244,
    "mehadia": 241,
    "drobeta": 242,
    "craiova": 160,
    "rimnicu_vilcea": 193,
    "fagaras": 178,
    "pitesti": 98,
    "bucharest": 0,
    "giurgiu": 77,
    "urziceni": 80,
    "hirsova": 151,
    "eforie": 161,
    "vaslui": 199,
    "iasi": 226,
    "neamt": 234
}
```

üìå **Exemplo**: Um GPS que sempre escolhe a rota com menor dist√¢ncia at√© o destino (em linha reta), sem considerar o tr√¢nsito.

---

### üî∏2.2 Busca A* (Busca em Estrela)

- Combina dois fatores:
  - `g(n)`: custo real at√© o n√≥ `n`
  - `h(n)`: estimativa heur√≠stica at√© o objetivo
  - `f(n) = g(n) + h(n)`
- Garante o **melhor caminho poss√≠vel** com heur√≠stica admiss√≠vel.
- Muito usada em mapas, jogos e rob√≥tica.
- No melhor dos casos, deve-se utilizar de dist√¢ncia euclidiana

**Exemplo de coordenadas:**
```python
# 2.1 A *
coordinates = {
    "oradea": (1, 5),
    "zerind": (2, 6),
    "arad": (3, 4),
    "sibiu": (5, 5),
    "timisoara": (4, 2),
    "lugoj": (6, 3),
    "mehadia": (7, 2),
    "drobeta": (8, 1),
    "craiova": (9, 2),
    "rimnicu_vilcea": (7, 5),
    "fagaras": (8, 6),
    "pitesti": (10, 4),
    "bucharest": (12, 5),
    "giurgiu": (13, 3),
    "urziceni": (12, 6),
    "vaslui": (14, 7),
    "iasi": (13, 8),
    "neamt": (12, 9),
    "hirsova": (14, 5),
    "eforie": (15, 4)
}

def euclidean_distance(node1, node2):
    x1, y1 = coordinates[node1]
    x2,y2 = coordinates[node2]
    return math.sqrt((x2 - x1) **2 + (y2 - y1) **2)
```

**Exemplo de c√≥digo:**
```python
def a_start_search_dynamic(graph, start, goal):
    priority_queue = [(euclidean_distance(start,goal), 0, start,[start])]
    heapq.heapify(priority_queue)
    visited = set()

    while priority_queue:
        f, g, current_node, path = heapq.heappop(priority_queue)

        if current_node == goal:
            return path, g
        if current_node in visited:
            continue
        visited.add(current_node)

        for neighbor, cost in graph[current_node].items():
            if neighbor not in visited:
                new_g = g + cost
                new_h = euclidean_distance(neighbor, goal)
                new_f = new_g + new_h
                heapq.heappush(priority_queue, (new_f, new_g, neighbor, path + [neighbor]))
    return None
```

üìå **Exemplo**: Um GPS que considera dist√¢ncia **e** tempo de deslocamento estimado.

---

## üìä Tabela de Complexidade das Estrat√©gias de Busca

| Estrat√©gia                       | Completa | √ìtima | Complexidade de Tempo | Complexidade de Espa√ßo |
|----------------------------------|----------|--------|------------------------|-------------------------|
| Busca em largura (amplitude)     | Sim      | Sim    | O(b^d)                 | O(b^d)                  |
| Custo uniforme                   | Sim      | Sim    | O(b^(1 + [C*/Œµ]))      | O(b^(1 + [C*/Œµ]))       |
| Busca em profundidade            | N√£o      | N√£o    | O(b^m)                 | O(m)                    |
| Profundidade limitada            | Depende  | N√£o    | O(b^l)                 | O(bl)                   |
| Aprofundamento iterativo         | Sim      | Sim    | O(b^d)                 | O(bd)                   |
| Busca bidirecional               | Sim      | Sim    | O(b^(d/2))             | O(b^(d/2))              |
| Busca gulosa                     | N√£o      | N√£o    | O(b^m)                 | O(b^m)                  |
| Busca A*                         | Sim      | Sim*   | O(b^d)                 | O(b^d)                  |


 üî†Legenda dos S√≠mbolos

- **b:** Fator de ramifica√ß√£o
    ‚Üí N√∫mero m√©dio de sucessores (filhos) por n√≥.

- **d:** Profundidade da solu√ß√£o √≥tima
    ‚Üí N√≠vel em que o objetivo pode ser encontrado pela primeira vez.

- **m:** Profundidade m√°xima do espa√ßo de estados
    ‚Üí Maior poss√≠vel profundidade da √°rvore de busca (pode ser infinito).

- **C***: Custo do caminho da solu√ß√£o √≥tima
    ‚Üí Soma dos custos das a√ß√µes que levam at√© a meta, no menor caminho.

- **Œµ (√©psilon):** Menor incremento de custo entre dois n√≥s adjacentes
    ‚Üí Usado na complexidade da busca de custo uniforme para garantir progresso.

---

